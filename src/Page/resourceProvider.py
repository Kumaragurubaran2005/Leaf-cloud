import os
import base64
import requests
import threading
from time import sleep
from run_code import run_in_docker
from updateSender import send_update

# -------------------- CONFIG --------------------
workerId = "worker123"
SERVER_URL = "http://localhost:5000"
HEARTBEAT_INTERVAL = 5  # seconds

# -------------------- HEARTBEAT SYSTEM --------------------
def send_heartbeat(customerId):
    payload = {"workerId": workerId, "customerId": customerId}
    try:
        requests.post(f"{SERVER_URL}/heartbeat", json=payload)
    except requests.exceptions.RequestException as e:
        print("‚ö†Ô∏è Heartbeat error:", e)

def start_global_heartbeat(interval=HEARTBEAT_INTERVAL):
    stop_event = threading.Event()

    def loop():
        while not stop_event.is_set():
            send_heartbeat("idle")
            sleep(interval)

    threading.Thread(target=loop, daemon=True).start()
    return stop_event

def start_task_heartbeat(customerId, interval=HEARTBEAT_INTERVAL):
    stop_event = threading.Event()

    def heartbeat_loop():
        while not stop_event.is_set():
            send_heartbeat(customerId)
            sleep(interval)

    thread = threading.Thread(target=heartbeat_loop, daemon=True)
    thread.start()
    return stop_event

# -------------------- SERVER COMMUNICATION --------------------
def check_server():
    try:
        r = requests.get(f"{SERVER_URL}/areyouthere")
        r.raise_for_status()
        return r.json().get("iamthere", False)
    except requests.exceptions.RequestException:
        return False

def claim_task():
    try:
        payload = {"workerId": workerId}
        r = requests.post(f"{SERVER_URL}/gettask", json=payload)
        r.raise_for_status()
        data = r.json()
        if not data.get("taskId"):
            return None, None, None
        return data["customerId"], data["taskId"], data["files"]
    except requests.exceptions.RequestException as e:
        print("‚ö†Ô∏è Claim task error:", e)
        return None, None, None

def save_files(customerId, files):
    folder_path = os.path.join(os.getcwd(), customerId)
    os.makedirs(folder_path, exist_ok=True)

    code_path = os.path.join(folder_path, "code_file.py")
    with open(code_path, "wb") as f:
        f.write(base64.b64decode(files["code"]))

    if files.get("dataset"):
        dataset_path = os.path.join(folder_path, "dataset_file.csv")
        with open(dataset_path, "wb") as f:
            f.write(base64.b64decode(files["dataset"]))

    if files.get("requirement"):
        req_path = os.path.join(folder_path, "requirements.txt")
        with open(req_path, "wb") as f:
            f.write(base64.b64decode(files["requirement"]))

    return folder_path

# -------------------- UPLOAD RESULT --------------------
def upload_result(customerId, workerId, result_file_path, usage_file_path):
    with open(result_file_path, "rb") as result_file, open(usage_file_path, "rb") as usage_file:
        files = {"result": result_file, "usage": usage_file}
        payload = {"workerId": workerId, "customerId": customerId}
        try:
            r = requests.post(f"{SERVER_URL}/uploadresult", files=files, data=payload)
            r.raise_for_status()
            response = r.json()
            if response.get("resp"):
                print(f"‚úÖ Result uploaded successfully. Pending workers: {response.get('pendingWorkers')}")
            else:
                print("‚ùå Upload failed:", response.get("message"))
        except requests.exceptions.RequestException as e:
            print("‚ùå Result upload failed:", e)

# -------------------- MAIN LOOP --------------------
def main_worker():
    global customerId
    while True:
        if not check_server():
            print("‚ö†Ô∏è Server not available. Retrying in 5s...")
            sleep(5)
            continue

        customerId, taskId, files = claim_task()
        if not taskId:
            print("‚ÑπÔ∏è No task available. Retrying in 5s...")
            sleep(5)
            continue

        print(f"‚ö° Claimed task {taskId} for customer {customerId}")
        folder_path = save_files(customerId, files)

        heartbeat_stop = start_task_heartbeat(customerId)
        print("üê≥ Running code in Docker...")

        try:
            # Run in Docker; this already creates result_output.txt and usage_log.txt
            result = run_in_docker(
                folder_path,
                workerId=workerId,
                customerId=customerId,
                code_file="code_file.py",
                requirements_file="requirements.txt",
                cpu_limit=1.0,
                mem_limit="512m"
            )
            print(f"‚úÖ Docker finished. Exit code: {result['exit_code']}")
        except Exception as e:
            print(f"‚ùå Docker execution failed: {e}")
            send_update(customerId, f"docker_failed: {e}", workerId)
            heartbeat_stop.set()
            continue

        # File paths generated by run_in_docker
        result_file = os.path.join(folder_path, "result_output.txt")
        usage_file = os.path.join(folder_path, "usage_log.txt")

        # Upload result and usage
        upload_result(customerId, workerId, result_file, usage_file)

        send_update(customerId, "completed", workerId)
        heartbeat_stop.set()
        print("‚úÖ Task completed. Waiting for next task...")
        sleep(5)

if __name__ == "__main__":
    start_global_heartbeat()  # Always running
    main_worker()
